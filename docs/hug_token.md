# Hugging Face アクセストークンの発行と設定手順

ローカルLLM（vLLM等）で `openai/gpt-oss-20b` などのモデルをダウンロード・実行するために必要な、Hugging Faceアクセストークンの取得および環境への設定手順です。

## 1. Webブラウザでのトークン発行手順

Hugging Faceの公式サイト上で、モデルのダウンロード権限を持つトークン（Read権限）を発行します。

1. **Hugging Faceにログイン**
   [Hugging Face公式サイト](https://huggingface.co/) にアクセスし、ログインします。
   <small>※アカウントがない場合は `Sign Up` から登録してください。</small>

2. **設定画面へ移動**
   右上のプロフィールアイコンをクリックし、メニューから **[Settings]** を選択します。

3. **アクセストークン管理へ**
   左側のサイドバーメニューから **[Access Tokens]** をクリックします。

4. **新規トークンの作成**
   * **[Create new token]** ボタンをクリックします。
   * **Token type**: モデルのダウンロードのみに使用するため **`Read`** を選択します。
   * **Name**: 任意の名前を入力します（例: `local-llm-vllm`）。
   * **Create token** をクリックして作成を完了します。

5. **トークンのコピー**
   表示された `hf_` から始まる文字列をコピーし、控えておきます。

> [!IMPORTANT]
> **セキュリティ上の注意**
> トークンはパスワードと同様に扱ってください。GitHubの公開リポジトリなどに直接コミットしないよう注意しましょう。

---

## 2. 環境変数の設定 (Linux/Conda環境)

vLLMを実行するターミナルで、発行したトークンを環境変数に設定します。

### 一時的な設定（現在のセッションのみ）

ターミナルを開き、以下のコマンドを実行します。

```bash
# "あなたのトークン文字列" の部分を、先ほどコピーしたhf_...に置き換えてください
export HUGGINGFACE_HUB_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
